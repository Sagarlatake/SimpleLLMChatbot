{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T23:32:08.875622Z",
     "start_time": "2025-10-14T23:30:37.678275Z"
    }
   },
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "    print('env variable loaded...')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"Llama-3.3-70B-Versatile\", model_provider=\"groq\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "# open AI format\n",
    "# print(\"Open AI formatted calls:\")\n",
    "# response = model.invoke(\"Hello\")\n",
    "# print(response.content)\n",
    "# response = model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "# print(response.content)\n",
    "# response = model.invoke([HumanMessage(\"Hello\")])\n",
    "# print(response.content)\n",
    "\n",
    "\n",
    "# streaming\n",
    "\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")\n",
    "\n",
    "\n",
    "# using Prompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "print('Prompt created using prompt template')\n",
    "print(prompt)\n",
    "print(prompt.to_messages())\n",
    "print('Model Response:')\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env variable loaded...\n",
      "Ciao!\n",
      "|C|iao|!||Prompt created using prompt template\n",
      "messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n",
      "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n",
      "Model Response:\n",
      "Ciao!\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
